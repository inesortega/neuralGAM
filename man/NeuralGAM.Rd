% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/NeuralGAM.R
\name{NeuralGAM}
\alias{NeuralGAM}
\title{Fit a NeuralGAM model}
\usage{
NeuralGAM(
  formula,
  data,
  num_units,
  family = "gaussian",
  learning_rate = 0.001,
  kernel_initializer = "glorot_normal",
  w_train = NULL,
  bf_threshold = 0.001,
  ls_threshold = 0.1,
  max_iter_backfitting = 10,
  max_iter_ls = 10,
  ...
)
}
\arguments{
\item{formula}{A GAM formula. You can add smooth terms using \code{s()}.}

\item{data}{A data frame containing the model response variable and covariates
required by the formula. Additonal terms not present in the formula will be ignored.}

\item{num_units}{Defines the architecture of each neural network.
If a scalar value is provided, a single hidden layer neural network with that number of units is used.
If a list of values is provided, a multi-layer neural network with each element of the list defining
the number of hidden units on each hidden layer is used.}

\item{family}{A description of the link function used in the model
(defaults to \code{gaussian}). Set \code{family="gaussian"} for linear
regression and \code{family="binomial"} for logistic regression.}

\item{learning_rate}{Learning rate for the neural network optimizer.}

\item{kernel_initializer}{Kernel initializer for the Dense layers.
Defaults to Xavier Initializer (\code{glorot_normal}).}

\item{bf_threshold}{Convergence criterion of the backfitting algorithm.
Defaults to \code{0.001}}

\item{ls_threshold}{Convergence criterion of the local scoring algorithm.
Defaults to \code{0.1}}

\item{max_iter_backfitting}{An integer with the maximum number of iterations
of the backfitting algorithm. Defaults to \code{10}.}

\item{max_iter_ls}{An integer with the maximum number of iterations of the
local scoring Algorithm. Defaults to \code{10}.}

\item{...}{Other parameters.}

\item{sample_weights}{Optional sample weights.}
}
\value{
A trained NeuralGAM object. Use \code{summary(ngam)} to see details.
}
\description{
Main function to fit a NeuralGAM model. The function builds one
neural network to attend to each feature in x, using the
backfitting and local scoring algorithms to fit a weighted additive model
using neural networks as function approximators. The adjustment of the
dependent variable and the weights is determined by the distribution of the
response \code{y}, adjusted by the \code{family} parameter.
}
\examples{

library(NeuralGAM)
data(train)

ngam <- NeuralGAM( y ~ X1 + s(X0) + s(X2), data = train,
num_units = 1024, family = "gaussian",
learning_rate = 0.001, bf_threshold = 0.001,
max_iter_backfitting = 10, max_iter_ls = 10
)

ngam

data(test)
X_test <- test[c("X0", "X1", "X2")]
# Obtain linear predictor
eta <- predict(object = ngam, x = X_test, type = "link")
# Obtain each component of the linear predictor separately on each column of a data.frame
terms <- predict(object = ngam, x = X_test, type = "terms")
}
\author{
Ines Ortega-Fernandez, Marta Sestelo.
}
