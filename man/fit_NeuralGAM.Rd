% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fit_NeuralGAM.R
\name{fit_NeuralGAM}
\alias{fit_NeuralGAM}
\title{Fit a NeuralGAM model}
\usage{
fit_NeuralGAM(
  x,
  y,
  num_units,
  learning_rate,
  family = "gaussian",
  w_train = NULL,
  bf_threshold = 1e-05,
  ls_threshold = 0.1,
  max_iter_backfitting = 10,
  max_iter_ls = 10
)
}
\arguments{
\item{x}{A data frame containing all the covariates.}

\item{y}{A vector with the response values.}

\item{num_units}{number of hidden units (for shallow neural networks) or
list of hidden units per layer (i.e. \code{"list(32,32,32)"} generates a DNN
with three layers and \code{32} neurons per layer).}

\item{learning_rate}{learning rate for the neural network optimizer}

\item{family}{A description of the link function used in the model:
\code{"gaussian"} or \code{"binomial"}
Defaults to \code{"gaussian"}}

\item{w_train}{optional sample weights.}

\item{bf_threshold}{convergence criterion of the backfitting algorithm.
Defaults to \code{0.00001}}

\item{ls_threshold}{convergence criterion of the local scoring algorithm.
Defaults to \code{0.1}}

\item{max_iter_backfitting}{an integer with the maximum number of iterations
of the backfitting algorithm. Defaults to \code{10}.}

\item{max_iter_ls}{an integer with the maximum number of iterations of the
local scoring Algorithm. Defaults to \code{10}.}
}
\value{
y_hat, partial effects and learned eta
}
\description{
Main function to fit a NeuralGAM model. The function builds one
neural network to attend to each to each feature in x, using the
backfitting and local scoring algorithms to fit a weighted additive model
using neural networks as function approximators. The adjustment of the
dependent variable and the weights is determined by the distribution of the
response \code{"y"} (\code{"gaussian"} or #' \code{"binomial"}).
}
\examples{

library(NeuralGAM)
data(train)
head(train)
X_train = train[c('X0','X1','X2')]
fs_train = train[c('f(X0)','f(X1)','f(X2)')]
y_train = train['y']

ngam <- fit_NeuralGAM(num_units = 1024, learning_rate = 0.001, x=X_train,
              y = y_train, family = "gaussian", bf_threshold=0.00001,
              ls_threshold = 0.1, max_iter_backfitting = 10,
              max_iter_ls=10)
}
